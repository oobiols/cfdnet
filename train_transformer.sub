#!/bin/bash

#SBATCH --job-name=tfmer
#SBATCH -A amowli_lab_gpu
#SBATCH -p free-gpu              ## run on the gpu partition
#SBATCH -N 1                ## run on a single node
#SBATCH -n 40              ## request 1 task
#SBATCH -t 12:00:00      ## 2-day run time limit
#SBATCH --gres=gpu:V100:1   ## request 1 gpu of type V100


MASKING=1
EPOCHS=50
BATCHSIZE=256
PROJECTION=32
ATTENTION=4
R=100

python coarse_model_transformer.py -e $EPOCHS -lr 1e-4\
 -bs $BATCHSIZE\
 -rlr 1\
 -lcont $R \
 -lmomx $R \
 -lmomz $R \
 -m $MASKING \
 -ah $ATTENTION \
 -pr $PROJECTION \  
 > out-train-transformer-masking-$MASKING.txt
